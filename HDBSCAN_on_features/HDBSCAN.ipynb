{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '/home/shoaib/ZTFDataChallenge/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, base_directory + 'dmdt_Analysis/')\n",
    "from dmdt_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc=\"Lightcurves Processed\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['axes.grid'] = False\n",
    "# plt.style.use('seaborn-v0_8-colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the features by name\n",
    "features_by_name = pd.read_parquet(base_directory + 'original_features_by_name.parquet')\n",
    "# features_by_name = features_by_name.dropna(axis=0)\n",
    "# features_by_name = features_by_name.query(\"type in @qso_types\")\n",
    "### Sampling to save memory\n",
    "# features_by_name = features_by_name.sample(frac=0.1)\n",
    "\n",
    "### Loading the features by OID\n",
    "# features_by_oid = pd.read_parquet(base_directory + 'original_features_by_oid.parquet')\n",
    "# features_by_oid = features_by_oid.dropna(axis=0)\n",
    "# features_by_oid = features_by_oid.query(\"type in @qso_types\")\n",
    "### Sampling to save memory\n",
    "# features_by_oid = features_by_oid.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the lightcurves by name\n",
    "lightcurves_by_name = pd.read_pickle(base_directory + 'lightcurves_by_name_1day_binned.pkl')[['name', 'r_lightcurve','r_n_good_det','r_timespan_good','g_lightcurve','g_n_good_det','g_timespan_good']]\n",
    "# lightcurves_by_name = lightcurves_by_name.dropna(axis=0)\n",
    "# lightcurves_by_name = lightcurves_by_name.query(\"type in @qso_types\")\n",
    "### Sampling to save memory\n",
    "# lightcurves_by_name = lightcurves_by_name.sample(frac=0.1)\n",
    "\n",
    "### Loading the lightcurves by OID\n",
    "# lightcurves_by_oid = pd.read_pickle(base_directory + 'lightcurves_by_oid_1day_binned.pkl')[['oid_alerce', 'lightcurve','n_good_det','timespan_good']]\n",
    "# lightcurves_by_oid = lightcurves_by_oid.dropna(axis=0)\n",
    "# lightcurves_by_oid = lightcurves_by_oid.query(\"type in @qso_types\")\n",
    "### Sampling to save memory\n",
    "# lightcurves_by_oid = lightcurves_by_oid.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_by_name = features_by_name.merge(right=lightcurves_by_name, on='name', how='inner', suffixes=('feat', None))\n",
    "# features_by_oid = features_by_oid.merge(right=lightcurves_by_oid, on='oid_alerce', how='inner', suffixes=('feat', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['z'] + ['T2020_sigma2', 'mhps_ratio', 'mhps_low', 'mhps_high', 'Amplitude', 'AndersonDarling', 'Autocor_length',\n",
    "                 'Beyond1Std', 'Con', 'Eta_e', 'Gskew', 'MaxSlope', 'Mean', 'Meanvariance', 'MedianAbsDev', 'MedianBRP', 'PairSlopeTrend',\n",
    "                 'PercentAmplitude', 'Q31', 'PeriodLS_v2', 'Period_fit_v2', 'Psi_CS_v2', 'Psi_eta_v2', 'Rcs', 'Skew', 'SmallKurtosis',\n",
    "                 'Std', 'StetsonK', 'Pvar', 'ExcessVar', 'GP_DRW_sigma', 'GP_DRW_tau', 'SF_ML_amplitude', 'SF_ML_gamma', 'IAR_phi',\n",
    "                 'LinearTrend', 'Harmonics_mag_1', 'Harmonics_mag_2', 'Harmonics_mag_3', 'Harmonics_mag_4', 'Harmonics_mag_5',\n",
    "                 'Harmonics_mag_6', 'Harmonics_mag_7', 'Harmonics_phase_2', 'Harmonics_phase_3', 'Harmonics_phase_4', 'Harmonics_phase_5',\n",
    "                 'Harmonics_phase_6', 'Harmonics_phase_7', 'Harmonics_mse', 'mhps_non_zero', 'mhps_PN_flag']\n",
    "\n",
    "band_feature_names = ['z'] + ['r_' + feature_name for feature_name in feature_names[1:]] + ['g_' + feature_name for feature_name in feature_names[1:]]\n",
    "band_label_names = {i: feature_name for i, feature_name in enumerate(band_feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32163 rows in data right now.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "Q     19613\n",
       "A      3593\n",
       "QX     2429\n",
       "AX     1482\n",
       "QR     1283\n",
       "      ...  \n",
       "NX        2\n",
       "KX        1\n",
       "K         1\n",
       "KR        1\n",
       "NR        1\n",
       "Name: count, Length: 29, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### How big is data?\n",
    "data = features_by_name[['type'] + band_feature_names]\n",
    "\n",
    "print(f'There are {len(data)} rows in data right now.\\n')\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19701 rows in data right now.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "Q                          13159\n",
       "A                           2086\n",
       "QX                          1386\n",
       "QR                           809\n",
       "AX                           667\n",
       "                           ...  \n",
       "AR2                            5\n",
       "A2X                            3\n",
       "A2                             1\n",
       "NR                             1\n",
       "BL Lac-galaxy dominated        1\n",
       "Name: count, Length: 25, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ranges = {\n",
    "    'T2020_sigma2': (0, 0.2),\n",
    "    'mhps_ratio': (0, 1000),\n",
    "    'mhps_low': (0, 2),\n",
    "    'mhps_high': (0, 0.2),\n",
    "    'SmallKurtosis': (0, 20),\n",
    "    'ExcessVar': (0, 0.0004),\n",
    "    'GP_DRW_sigma': (0, 0.3),\n",
    "    'GP_DRW_tau': (0, 4000),\n",
    "    'SF_ML_amplitude': (0, 2),\n",
    "    'LinearTrend': (-0.003, 0.003),\n",
    "    'Harmonics_mag_1': (0, 400),\n",
    "    'Harmonics_mag_2': (0, 400),\n",
    "    'Harmonics_mag_3': (0, 400),\n",
    "    'Harmonics_mag_4': (0, 400),\n",
    "    'Harmonics_mag_5': (0, 400),\n",
    "    'Harmonics_mag_6': (0, 400),\n",
    "    'Harmonics_mag_7': (0, 400),\n",
    "    'Harmonics_mse': (0, 0.1)\n",
    "}\n",
    "\n",
    "for feature in feature_names:\n",
    "    if feature in feature_ranges:\n",
    "        range_min, range_max = feature_ranges[feature]\n",
    "        data = data[(data['r_' + feature] >= range_min) & (data['g_' + feature] <= range_max)]\n",
    "\n",
    "print(f'There are {len(data)} rows in data right now.\\n')\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19488 rows in data right now.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "Q                          13159\n",
       "A                           2085\n",
       "QX                          1386\n",
       "QR                           809\n",
       "AX                           666\n",
       "                           ...  \n",
       "AR2                            5\n",
       "A2X                            3\n",
       "A2                             1\n",
       "NR                             1\n",
       "BL Lac-galaxy dominated        1\n",
       "Name: count, Length: 25, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "print(f'There are {len(data)} rows in data right now.\\n')\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = (data[band_feature_names] - np.mean(data[band_feature_names], axis=0)) / np.std(data[band_feature_names], axis=0)\n",
    "data_array = data_array.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project to DIM 2 with umap, then HDB scan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(10, 4))\n",
    "    labels = labels if labels is not None else np.ones(X.shape[0])\n",
    "    probabilities = probabilities if probabilities is not None else np.ones(X.shape[0])\n",
    "    # Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    # The probability of a point belonging to its labeled cluster determines\n",
    "    # the size of its marker\n",
    "    proba_map = {idx: probabilities[idx] for idx in range(len(labels))}\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_index = (labels == k).nonzero()[0]\n",
    "        for ci in class_index:\n",
    "            ax.plot(\n",
    "                X[ci, 0],\n",
    "                X[ci, 1],\n",
    "                \"x\" if k == -1 else \"o\",\n",
    "                markerfacecolor=tuple(col),\n",
    "                markeredgecolor=\"k\",\n",
    "                markersize=4 if k == -1 else 1 + 5 * proba_map[ci],\n",
    "            )\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    preamble = \"True\" if ground_truth else \"Estimated\"\n",
    "    title = f\"{preamble} number of clusters: {n_clusters_}\"\n",
    "    if parameters is not None:\n",
    "        parameters_str = \", \".join(f\"{k}={v}\" for k, v in parameters.items())\n",
    "        title += f\" | {parameters_str}\"\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "som",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
